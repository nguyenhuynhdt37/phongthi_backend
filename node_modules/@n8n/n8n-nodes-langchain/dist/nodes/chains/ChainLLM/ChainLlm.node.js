"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.ChainLlm = void 0;
const n8n_workflow_1 = require("n8n-workflow");
const helpers_1 = require("../../../utils/helpers");
const N8nOutputParser_1 = require("../../../utils/output_parsers/N8nOutputParser");
const methods_1 = require("./methods");
const error_handling_1 = require("../../vendors/OpenAi/helpers/error-handling");
class ChainLlm {
    constructor() {
        this.description = {
            displayName: 'Basic LLM Chain',
            name: 'chainLlm',
            icon: 'fa:link',
            iconColor: 'black',
            group: ['transform'],
            version: [1, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6],
            description: 'A simple chain to prompt a large language model',
            defaults: {
                name: 'Basic LLM Chain',
                color: '#909298',
            },
            codex: {
                alias: ['LangChain'],
                categories: ['AI'],
                subcategories: {
                    AI: ['Chains', 'Root Nodes'],
                },
                resources: {
                    primaryDocumentation: [
                        {
                            url: 'https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.chainllm/',
                        },
                    ],
                },
            },
            inputs: `={{ ((parameter) => { ${methods_1.getInputs.toString()}; return getInputs(parameter) })($parameter) }}`,
            outputs: ["main"],
            credentials: [],
            properties: methods_1.nodeProperties,
        };
    }
    async execute() {
        this.logger.debug('Executing Basic LLM Chain');
        const items = this.getInputData();
        const returnData = [];
        for (let itemIndex = 0; itemIndex < items.length; itemIndex++) {
            try {
                const llm = (await this.getInputConnectionData("ai_languageModel", 0));
                const outputParser = await (0, N8nOutputParser_1.getOptionalOutputParser)(this);
                let prompt;
                if (this.getNode().typeVersion <= 1.3) {
                    prompt = this.getNodeParameter('prompt', itemIndex);
                }
                else {
                    prompt = (0, helpers_1.getPromptInputByType)({
                        ctx: this,
                        i: itemIndex,
                        inputKey: 'text',
                        promptTypeKey: 'promptType',
                    });
                }
                if (prompt === undefined) {
                    throw new n8n_workflow_1.NodeOperationError(this.getNode(), "The 'prompt' parameter is empty.");
                }
                const messages = this.getNodeParameter('messages.messageValues', itemIndex, []);
                const responses = await (0, methods_1.executeChain)({
                    context: this,
                    itemIndex,
                    query: prompt,
                    llm,
                    outputParser,
                    messages,
                });
                const shouldUnwrapObjects = this.getNode().typeVersion >= 1.6 || !!outputParser;
                responses.forEach((response) => {
                    returnData.push({
                        json: (0, methods_1.formatResponse)(response, shouldUnwrapObjects),
                    });
                });
            }
            catch (error) {
                if (error instanceof n8n_workflow_1.NodeApiError && (0, error_handling_1.isOpenAiError)(error.cause)) {
                    const openAiErrorCode = error.cause.error?.code;
                    if (openAiErrorCode) {
                        const customMessage = (0, error_handling_1.getCustomErrorMessage)(openAiErrorCode);
                        if (customMessage) {
                            error.message = customMessage;
                        }
                    }
                }
                if (this.continueOnFail()) {
                    returnData.push({ json: { error: error.message }, pairedItem: { item: itemIndex } });
                    continue;
                }
                throw error;
            }
        }
        return [returnData];
    }
}
exports.ChainLlm = ChainLlm;
//# sourceMappingURL=ChainLlm.node.js.map