"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.LmChatAnthropic = void 0;
const anthropic_1 = require("@langchain/anthropic");
const sharedFields_1 = require("../../../utils/sharedFields");
const searchModels_1 = require("./methods/searchModels");
const n8nLlmFailedAttemptHandler_1 = require("../n8nLlmFailedAttemptHandler");
const N8nLlmTracing_1 = require("../N8nLlmTracing");
const modelField = {
    displayName: 'Model',
    name: 'model',
    type: 'options',
    options: [
        {
            name: 'Claude 3.5 Sonnet(20241022)',
            value: 'claude-3-5-sonnet-20241022',
        },
        {
            name: 'Claude 3 Opus(20240229)',
            value: 'claude-3-opus-20240229',
        },
        {
            name: 'Claude 3.5 Sonnet(20240620)',
            value: 'claude-3-5-sonnet-20240620',
        },
        {
            name: 'Claude 3 Sonnet(20240229)',
            value: 'claude-3-sonnet-20240229',
        },
        {
            name: 'Claude 3.5 Haiku(20241022)',
            value: 'claude-3-5-haiku-20241022',
        },
        {
            name: 'Claude 3 Haiku(20240307)',
            value: 'claude-3-haiku-20240307',
        },
        {
            name: 'LEGACY: Claude 2',
            value: 'claude-2',
        },
        {
            name: 'LEGACY: Claude 2.1',
            value: 'claude-2.1',
        },
        {
            name: 'LEGACY: Claude Instant 1.2',
            value: 'claude-instant-1.2',
        },
        {
            name: 'LEGACY: Claude Instant 1',
            value: 'claude-instant-1',
        },
    ],
    description: 'The model which will generate the completion. <a href="https://docs.anthropic.com/claude/docs/models-overview">Learn more</a>.',
    default: 'claude-2',
};
const MIN_THINKING_BUDGET = 1024;
const DEFAULT_MAX_TOKENS = 4096;
class LmChatAnthropic {
    constructor() {
        this.methods = {
            listSearch: {
                searchModels: searchModels_1.searchModels,
            },
        };
        this.description = {
            displayName: 'Anthropic Chat Model',
            name: 'lmChatAnthropic',
            icon: 'file:anthropic.svg',
            group: ['transform'],
            version: [1, 1.1, 1.2, 1.3],
            defaultVersion: 1.3,
            description: 'Language Model Anthropic',
            defaults: {
                name: 'Anthropic Chat Model',
            },
            codex: {
                categories: ['AI'],
                subcategories: {
                    AI: ['Language Models', 'Root Nodes'],
                    'Language Models': ['Chat Models (Recommended)'],
                },
                resources: {
                    primaryDocumentation: [
                        {
                            url: 'https://docs.n8n.io/integrations/builtin/cluster-nodes/sub-nodes/n8n-nodes-langchain.lmchatanthropic/',
                        },
                    ],
                },
                alias: ['claude', 'sonnet', 'opus'],
            },
            inputs: [],
            outputs: ["ai_languageModel"],
            outputNames: ['Model'],
            credentials: [
                {
                    name: 'anthropicApi',
                    required: true,
                },
            ],
            properties: [
                (0, sharedFields_1.getConnectionHintNoticeField)(["ai_chain", "ai_chain"]),
                {
                    ...modelField,
                    displayOptions: {
                        show: {
                            '@version': [1],
                        },
                    },
                },
                {
                    ...modelField,
                    default: 'claude-3-sonnet-20240229',
                    displayOptions: {
                        show: {
                            '@version': [1.1],
                        },
                    },
                },
                {
                    ...modelField,
                    default: 'claude-3-5-sonnet-20240620',
                    options: (modelField.options ?? []).filter((o) => 'name' in o && !o.name.toString().startsWith('LEGACY')),
                    displayOptions: {
                        show: {
                            '@version': [{ _cnd: { lte: 1.2 } }],
                        },
                    },
                },
                {
                    displayName: 'Model',
                    name: 'model',
                    type: 'resourceLocator',
                    default: {
                        mode: 'list',
                        value: 'claude-3-7-sonnet-20250219',
                        cachedResultName: 'Claude 3.7 Sonnet',
                    },
                    required: true,
                    modes: [
                        {
                            displayName: 'From List',
                            name: 'list',
                            type: 'list',
                            placeholder: 'Select a model...',
                            typeOptions: {
                                searchListMethod: 'searchModels',
                                searchable: true,
                            },
                        },
                        {
                            displayName: 'ID',
                            name: 'id',
                            type: 'string',
                            placeholder: 'Claude Sonnet',
                        },
                    ],
                    description: 'The model. Choose from the list, or specify an ID. <a href="https://docs.anthropic.com/claude/docs/models-overview">Learn more</a>.',
                    displayOptions: {
                        show: {
                            '@version': [{ _cnd: { gte: 1.3 } }],
                        },
                    },
                },
                {
                    displayName: 'Options',
                    name: 'options',
                    placeholder: 'Add Option',
                    description: 'Additional options to add',
                    type: 'collection',
                    default: {},
                    options: [
                        {
                            displayName: 'Maximum Number of Tokens',
                            name: 'maxTokensToSample',
                            default: DEFAULT_MAX_TOKENS,
                            description: 'The maximum number of tokens to generate in the completion',
                            type: 'number',
                        },
                        {
                            displayName: 'Sampling Temperature',
                            name: 'temperature',
                            default: 0.7,
                            typeOptions: { maxValue: 1, minValue: 0, numberPrecision: 1 },
                            description: 'Controls randomness: Lowering results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive.',
                            type: 'number',
                            displayOptions: {
                                hide: {
                                    thinking: [true],
                                },
                            },
                        },
                        {
                            displayName: 'Top K',
                            name: 'topK',
                            default: -1,
                            typeOptions: { maxValue: 1, minValue: -1, numberPrecision: 1 },
                            description: 'Used to remove "long tail" low probability responses. Defaults to -1, which disables it.',
                            type: 'number',
                            displayOptions: {
                                hide: {
                                    thinking: [true],
                                },
                            },
                        },
                        {
                            displayName: 'Top P',
                            name: 'topP',
                            default: 1,
                            typeOptions: { maxValue: 1, minValue: 0, numberPrecision: 1 },
                            description: 'Controls diversity via nucleus sampling: 0.5 means half of all likelihood-weighted options are considered. We generally recommend altering this or temperature but not both.',
                            type: 'number',
                            displayOptions: {
                                hide: {
                                    thinking: [true],
                                },
                            },
                        },
                        {
                            displayName: 'Enable Thinking',
                            name: 'thinking',
                            type: 'boolean',
                            default: false,
                            description: 'Whether to enable thinking mode for the model',
                        },
                        {
                            displayName: 'Thinking Budget (Tokens)',
                            name: 'thinkingBudget',
                            type: 'number',
                            default: MIN_THINKING_BUDGET,
                            description: 'The maximum number of tokens to use for thinking',
                            displayOptions: {
                                show: {
                                    thinking: [true],
                                },
                            },
                        },
                    ],
                },
            ],
        };
    }
    async supplyData(itemIndex) {
        const credentials = await this.getCredentials('anthropicApi');
        const version = this.getNode().typeVersion;
        const modelName = version >= 1.3
            ? this.getNodeParameter('model.value', itemIndex)
            : this.getNodeParameter('model', itemIndex);
        const options = this.getNodeParameter('options', itemIndex, {});
        let invocationKwargs = {};
        const tokensUsageParser = (llmOutput) => {
            const usage = llmOutput?.usage ?? {
                input_tokens: 0,
                output_tokens: 0,
            };
            return {
                completionTokens: usage.output_tokens,
                promptTokens: usage.input_tokens,
                totalTokens: usage.input_tokens + usage.output_tokens,
            };
        };
        if (options.thinking) {
            invocationKwargs = {
                thinking: {
                    type: 'enabled',
                    budget_tokens: options.thinkingBudget ?? MIN_THINKING_BUDGET,
                },
                max_tokens: options.maxTokensToSample ?? DEFAULT_MAX_TOKENS,
                top_k: undefined,
                top_p: undefined,
                temperature: undefined,
            };
        }
        const model = new anthropic_1.ChatAnthropic({
            anthropicApiKey: credentials.apiKey,
            modelName,
            maxTokens: options.maxTokensToSample,
            temperature: options.temperature,
            topK: options.topK,
            topP: options.topP,
            callbacks: [new N8nLlmTracing_1.N8nLlmTracing(this, { tokensUsageParser })],
            onFailedAttempt: (0, n8nLlmFailedAttemptHandler_1.makeN8nLlmFailedAttemptHandler)(this),
            invocationKwargs,
        });
        return {
            response: model,
        };
    }
}
exports.LmChatAnthropic = LmChatAnthropic;
//# sourceMappingURL=LmChatAnthropic.node.js.map